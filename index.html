<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Mémoire Hugo Sainte-Marie</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
  <link rel="stylesheet" href="css/main.min.css" />
  <script src="js/jquery-3.2.1.min.js"></script>
  <script src="js/main.js"></script>
</head>

<body class="stackedit">
  <div class="stackedit__left">
    <div class="stackedit__toc">
      
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#algorithmes">Algorithmes</a>
<ul>
<li><a href="#quest-ce-quun-algorithme-">Qu’est-ce qu’un algorithme ?</a>
<ul>
<li><a href="#instructions-et-résultat">Instructions et résultat</a></li>
<li><a href="#les-algorithmes-symboliques">Les algorithmes symboliques</a></li>
</ul>
</li>
<li><a href="#approche-technico-historique">Approche technico-historique</a>
<ul>
<li><a href="#de-la-main-à-la-machine">De la main à la machine</a></li>
<li><a href="#jacquard-ou-le-tissage-programmé">Jacquard, ou le tissage programmé</a></li>
<li><a href="#la-machine-analytique-de-babbage">La machine analytique de Babbage</a></li>
<li><a href="#la-révolution-turing">La révolution Turing</a></li>
</ul>
</li>
<li><a href="#distinctions-définitionnelles">Distinctions définitionnelles</a>
<ul>
<li><a href="#de-lalgorithme-au-programme">De l’algorithme au programme</a></li>
<li><a href="#de-lordinateur-à-linformatique">De l’ordinateur à l’informatique</a></li>
</ul>
</li>
<li><a href="#approche-fondamentale">Approche fondamentale</a>
<ul>
<li><a href="#séquence">Séquence</a></li>
<li><a href="#affectation">Affectation</a></li>
<li><a href="#itération">Itération</a></li>
<li><a href="#condition">Condition</a></li>
</ul>
</li>
<li><a href="#algorithmes-pour-quoi-faire-">Algorithmes, pour quoi faire ?</a>
<ul>
<li><a href="#contextes-dusage-contemporains">Contextes d’usage contemporains</a></li>
<li><a href="#quatre-familles-de-calcul-numérique">Quatre familles de calcul numérique</a></li>
<li><a href="#intelligences-artificielles">Intelligences artificielles</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#écritures">Écriture(s)</a>
<ul>
<li><a href="#quest-ce-que-lécriture-">Qu’est-ce que l’écriture ?</a></li>
<li><a href="#des-langages-naturels-aux-langages-artificiels">Des langages naturels aux langages artificiels</a></li>
<li><a href="#lécriture-algorithmique">L’écriture algorithmique</a>
<ul>
<li><a href="#état-de-lart-systèmes…">État de l’art (systèmes…)</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
  </div>
  <div class="stackedit__right">
    <div class="stackedit__html">
      <h1 id="introduction">Introduction</h1>
<ul>
<li>Qu’est-ce qui se joue en terme de design ?</li>
<li>Pourquoi traiter ce sujet ? Pourquoi je travaille sur ça ? Pas juste un coup de cœur personnel mais une ambition plus large.</li>
<li>Quel est le problème intellectuel, quelle est la difficulté ?</li>
<li>Montrer l’actualité du sujet (Abiteboul &amp; Dowek, Cardon)</li>
<li>Différents contextes : montrer les situations où il y a un problème à traiter</li>
<li>Enjeux : différents aspects, points de vue qui vont déterminer le positionnement. Montrer que les problèmes sont larges même si l’on en traite qu’une partie.</li>
</ul>
<h1 id="algorithmes">Algorithmes</h1>
<h2 id="quest-ce-quun-algorithme-">Qu’est-ce qu’un algorithme ?</h2>
<h3 id="instructions-et-résultat">Instructions et résultat</h3>
<p>Un algorithme est une suite finie d’instructions qui vise à être exécutée afin de produire un résultat. Pour comprendre ou enseigner la notion d’algorithme, on fait bien souvent appel à des cas concrets que l’on rencontre dans la vie quotidienne. Une recette de cuisine, par exemple, constitue un algorithme : on y trouve des <em>entrées</em> (les ingrédients, quantités, ustensiles utilisés) ainsi que des instructions (casser en morceaux, cuire au bain-marie, couper en dés). Enfin, le résultat obtenu lorsqu’on suit minutieusement cette recette de cuisine est, bien évidemment, le plat préparé. Cette vision nous fournit une première définition du concept d’algorithme, donnée par Serge Abiteboul<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup> et Gilles Dowek<sup class="footnote-ref"><a href="#fn2" id="fnref2">2</a></sup>.</p>
<blockquote>
<p>Un algorithme est un procédé qui permet de résoudre un problème, sans avoir besoin d’inventer une solution à chaque fois. Avec cette définition, il est clair que, depuis l’aube de l’humanité, nous inventons, utilisons et transmettons des algorithmes : cuisine, taille du silex, pêche à la ligne, culture des lentilles et du blé, etc.<sup class="footnote-ref"><a href="#fn3" id="fnref3">3</a></sup></p>
</blockquote>
<h3 id="les-algorithmes-symboliques">Les algorithmes symboliques</h3>
<p>Dans cette définition générique de la notion d’algorithmes s’inscrit une catégorie spécifique plus réduite, un ensemble que l’on nomme <em>algorithmes symboliques</em>. Ceux-ci manipulent des symboles écrits : chiffres, lettres, assemblés en nombres, en mots et en phrases, et vecteurs de sens. Étymologiquement, le terme <em>algorithme</em> est d’ailleurs issu de la combinaison du mot latin <em>algorismus</em> – dérivé du nom du mathématicien Al-Khwarizmi<sup class="footnote-ref"><a href="#fn4" id="fnref4">4</a></sup> – et du mot grec <em>arithmos</em>, qui signifie “nombre”. Cette proximité entre les notions d’algorithmique et de mathématiques s’est confirmé grâce aux progrès techniques des deux siècles passés. À ce jour, par abus de langage et en raison de notre contexte technologique contemporain, la notion d’algorithmes symboliques a presque remplacé celle, plus générique, d’algorithmes : l’informatique a orienté l’emploi même du mot.</p>
<h2 id="approche-technico-historique">Approche technico-historique</h2>
<h3 id="de-la-main-à-la-machine">De la main à la machine</h3>
<p>Remontons aux origines des algorithmes symboliques, il y a 5&nbsp;000 ans. À cette époque, les mathématiciens ont déjà mis au point des algorithmes servant à résoudre des calculs algébriques simples tels que des additions et des multiplications, mais ceux-ci sont exécutés à la main, par des personnes en chair et en os. Des tâches répétitives qu’on aurait tout intérêt à déléguer aux machines, afin que celles-ci s’effectuent <em>mécaniquement</em>.</p>
<p>S’ensuivent cinq millénaires d’innovations techniques. Les premiers abaques<sup class="footnote-ref"><a href="#fn5" id="fnref5">5</a></sup>, suivis quelques siècles plus tard de leurs proches dérivés, les bouliers, assistent les hommes dans ces calculs mais ne sont pas encore autonomes. Au Moyen Âge, les cloches au sommet des cathédrales sonnent chaque heure sans intervention humaine : ce sont les premières machines capables d’exécuter des algorithmes symboliques. En 1642, l’inventeur français Blaise Pascal<sup class="footnote-ref"><a href="#fn6" id="fnref6">6</a></sup> met au point la première machine à calculer, qu’il nomme “machine arithmétique” ; elle est retravaillée quelques 30 ans plus tard par Gottfried Leibniz<sup class="footnote-ref"><a href="#fn7" id="fnref7">7</a></sup> qui y ajoute une interface permettant de réaliser de façon automatique des multiplications et des divisions.</p>
<h3 id="jacquard-ou-le-tissage-programmé">Jacquard, ou le tissage programmé</h3>
<p>En 1801, l’inventeur lyonnais Joseph Jacquard met au point un système de métier à tisser qui portera son nom : le fameux “métier Jacquard”. Celui-ci combine les métiers à tisser classiques avec le principe de cartes perforées inventé en 1728 par Jean-Baptiste Falcon – qui lui-même reprenait l’idée des rubans perforés que Basile Bouchon, son maître, proposait trois ans plus tôt. En perçant ou non un trou à un emplacement spécifique d’une carte, on peut programmer la machine : une fois insérée en <em>entrée</em> de la machine,  les cartes guident les crochets qui soulèvent les “fils de chaînes” – dont l’agencement produit le motif sur le textile tissé. Ce dispositif est souvent considéré comme la première forme de stockage d’informations binaires (<em>tout</em> ou <em>rien</em>, <em>vrai</em> ou <em>faux</em>), et le métier Jacquard comme l’ancêtre de l’ordinateur.</p>
<p>Mais ces machines ne sont pas encore des ordinateurs à proprement parler. Il leur manque pour atteindre ce statut une caractéristique majeure : l’universalité. En effet,  les exemples de machines cités plus haut n’ont chacun qu’une fonction ; là où un ordinateur est polyvalent, <em>universel</em>, capable d’exécuter n’importe quel algorithme symbolique imaginable : en résumé, une “machine à tout faire”.</p>
<h3 id="la-machine-analytique-de-babbage">La machine analytique de Babbage</h3>
<p>Au cours du XX<sup>ème</sup> siècle, l’apparition des premières <em>machines analytiques</em> va transformer les usages des algorithmes. En 1834, le visionnaire britannique Charles Babbage<sup class="footnote-ref"><a href="#fn8" id="fnref8">8</a></sup> débute le développement d’une machine d’un concept alors nouveau, qu’il qualifie de “machine analytique”. Celle-ci reprend la principe des machines à calculer mécaniques qui existent alors depuis plusieurs siècles déjà. Mais l’inventeur a l’idée d’ajouter à ces systèmes le principe des cartes perforées apparues avec les métiers Jacquard. Les composants de cette machine sont similaires à ceux qui composent un ordinateur moderne.</p>
<blockquote>
<ul>
<li>un dispositif d’entrée comporte deux lecteurs de cartes perforées (instructions et données) ; ces cartes sont issues des techniques du métier à tisser.</li>
<li>un organe de commande gère le transfert des nombres et leur mise en ordre pour le traitement ;</li>
<li>un moulin est chargé d’exécuter les opérations sur les nombres ;</li>
<li>un magasin permet de stocker les résultats intermédiaires ou finaux ;
trois types d’imprimantes sont prévus.<sup class="footnote-ref"><a href="#fn9" id="fnref9">9</a></sup></li>
</ul>
</blockquote>
<p>Pendant qu’il travaille sur ce projet, Babbage entre en correspondance avec Ada Lovelace. Pionnière de la science informatique, c’est elle qui, en 1843, sera à l’origine du premier algorithme destiné à être exécuté sur une machine : la machine à différences de Charles Babbage. Cet algorithme, considéré comme le premier programme informatique à proprement parler, sert alors à calculer la suite des nombres de Bernouilli<sup class="footnote-ref"><a href="#fn10" id="fnref10">10</a></sup>. Ada Lovelace est ainsi connue comme la première programmeuse de l’histoire.</p>
<h3 id="la-révolution-turing">La révolution Turing</h3>
<p>Les travaux de Lovelace et Babbage trouvent écho un siècle plus tard, dans les années 1930, grâce notamment aux recherches d’Alan Turing<sup class="footnote-ref"><a href="#fn11" id="fnref11">11</a></sup>. Cet inventeur, figure emblématique de la recherche mathématico-scientifique du XX<sup>ème</sup> siècle, conçoit en 1936 la “machine de Turing”, en vue de donner une définition précise au concept d’algorithme et à sa représentation formelle et technique de “procédure mécanique”.</p>
<blockquote>
<p>[La machine de Turing] consiste en deux éléments principaux :</p>
<ol>
<li>une machine représentée par une tête de lecture/écriture susceptible de se trouver dans un nombre fini d’états,</li>
<li>une bande (magnétique par exemple) de longueur infinie […] devant laquelle se meut la tête de lecture et qui alimente en données cette machine. […]</li>
</ol>
<p>Turing montre qu’une partie de la bande peut contenir la description de la table d’actions élémentaires d’une autre machine de Turing : une machine peut en simuler une autre. C’est grâce à cette construction schématique […] que Turing peut démontrer qu’il existe des machines de Turing dites universelles capables d’imiter toute autre machine de Turing. <sup class="footnote-ref"><a href="#fn12" id="fnref12">12</a></sup></p>
</blockquote>
<p>Turing illustre ainsi la notion d’<em>universalité</em> telle qu’elle avait été formulé par Lovelace et Babbage. La machine de Turing universelle est considérée comme la genèse des travaux de John von Neumann, qui en 1945 propose un modèle utilisé encore aujourd’hui dans nos ordinateurs modernes : l’architecture de von Neumann.</p>
<blockquote>
<p>L’architecture de von Neumann décompose l’ordinateur en quatre parties distinctes :</p>
<ul>
<li>l’unité arithmétique et logique (UAL) ou unité de traitement, qui effectue les opérations de base ;</li>
<li>l’unité de contrôle, qui est chargée du séquençage des opérations ;</li>
<li>la mémoire, qui contient à la fois les données et le programme qui indique à l’unité de contrôle quels calculs faire sur ces données. La mémoire se divise en mémoire vive (programmes et données en cours de fonctionnement) et mémoire de masse (programmes et données de base de la machine) ;</li>
<li>les dispositifs d’entrées-sorties, qui permettent de communiquer avec le monde extérieur.<sup class="footnote-ref"><a href="#fn13" id="fnref13">13</a></sup></li>
</ul>
</blockquote>
<p>En transposant ces composantes dans notre vocabulaire matériel contemporain, on confirme la proximité entre ce modèle, vieux de plus de 70 ans, et les ordinateurs que nous utilisons au quotidien :</p>
<ul>
<li>le processeur effectue les opérations ;</li>
<li>la mémoire vive (<abbr title="Random Access Memory">RAM</abbr>) stocke les données en cours d’utilisation ; et les disques durs – ou autres supports de stockage – contiennent des données pérennes ;</li>
<li>les périphériques en tout genre permettent l’interaction en <em>entrée</em> (clavier, souris, écran tactile, microphone, caméra, port <abbr title="Universal Serial Bus">USB</abbr>, lecteur de disque, etc.) et en <em>sortie</em> (écran, haut-parleurs, etc.)</li>
</ul>
<p>On observe une intime corrélation entre les notions d’algorithmes – et plus spécifiquement les algorithmes symboliques – et celles de programmes, ordinateurs et donc informatique. Toutefois, la proximité de ces concepts ne doit pas laisser place à la confusion ; il faut donc définir ces termes plus spécifiquement.</p>
<h2 id="distinctions-définitionnelles">Distinctions définitionnelles</h2>
<h3 id="de-lalgorithme-au-programme">De l’algorithme au programme</h3>
<p>Un programme informatique est une suite d’instructions qui effectue une ou plusieurs tâches spécifiques lorsqu’elle est exécutée par un ordinateur.<sup class="footnote-ref"><a href="#fn14" id="fnref14">14</a></sup> L’universitaire français Franck Varenne attire notre attention sur une possible origine de la confusion entre algorithmes et programmes. Il cite Charles Hoare, professeur et informaticien britannique, également connu pour la conception de nombreux algorithmes encore utilisés aujourd’hui. Hoare déclare que “la programmation informatique est une science exacte en ce que toutes les propriétés d’un programme […] peuvent être découvertes à partir du texte du programme lui-même au moyen de raisonnement purement déductif.” Varenne y oppose l’argumentation de James Fetzer, philosophe américain spécialisé notamment en informatique : la vision de Hoare amène à confondre les algorithmes et les programmes. Selon lui, rien n’implique une exacte similitude entre le comportement supposé du programme – à la lecture donc – et les conséquences réelles de son exécution sur la machine.</p>
<blockquote>
<p>Les algorithmes sont des solutions formelles (abstraites en ce sens) et effectives pour certains problèmes bien formulés. Les programmes chargés en mémoire (exécutables) sont en revanche des modèles causaux (car physiques) de ces algorithmes. Alors que les algorithmes sont des modèles abstraits des programmes exécutables, les programmes exécutables sont des modèles causaux des algorithmes.<sup class="footnote-ref"><a href="#fn15" id="fnref15">15</a></sup></p>
</blockquote>
<p>Varenne qualifie donc ces modèles d’<em>imparfaits</em> : le programme ne peut jamais être vérifié formellement, mais seulement de façon empirique. En effet, on peut établir la validité d’un programme, notamment en développant une sémantique formelle qui régule le <em>code</em> écrit par le programmeur. On résout alors les erreurs de programmation : variables sans valeur définie, fautes de syntaxe, structure erronée ou illogique, etc. Toutefois, la machine peut elle-même faire preuve de dysfonctionnement de fait même de sa dimension physique : processeur défectueux, espace de stockage corrompu, mémoire vive saturée, etc.</p>
<p>Cette marge d’incertitude entre le programme que l’on voit et ce que l’on obtient lorsqu’il est exécuté a été baptisé WYSINWYX, pour <em>What You See Is Not What You eXecute</em> – littéralement “ce que vous voyez n’est pas ce que vous exécutez”.<sup class="footnote-ref"><a href="#fn16" id="fnref16">16</a></sup> Cet acronyme est une référence au paronyme duquel il est inspiré : le terme WYSIWYG —<em>What You See Is What You Get</em>, soit “ce que vous voyez est ce que vous obtenez” – désigne, en informatique, les interfaces utilisateurs où l’on compose directement le résultat final souhaité.<sup class="footnote-ref"><a href="#fn17" id="fnref17">17</a></sup></p>
<p><code>@TODO</code></p>
<ul>
<li>WYSINWYX : l’erreur comme opportunité créatrice</li>
<li>Programme informatique, langage de programmation, langage machine</li>
</ul>
<h3 id="de-lordinateur-à-linformatique">De l’ordinateur à l’informatique</h3>
<p>La définition du terme “ordinateur”, dans son sens admis populairement, se base sur les travaux de Turing – comme évoqués dans la partie <em><a href="#la-r%C3%A9volution-turing">La révolution Turing</a></em>.</p>
<blockquote>
<p>Un ordinateur est un système de traitement de l’information programmable tel que défini par Turing et qui fonctionne par la lecture séquentielle d’un ensemble d’instructions, organisées en programmes, qui lui font exécuter des opérations logiques et arithmétiques.</p>
</blockquote>
<p>Les composants technologiques des ordinateurs modernes traitent des informations <em>binaires</em>. Là où les cartes perforées de Falcon utilisait des trous ou des pleins pour signifier un des deux états uniques qui composent un <em>bit</em><sup class="footnote-ref"><a href="#fn18" id="fnref18">18</a></sup>, nos ordinateurs, dont le fonctionnement est basé sur l’électricité, utilisent pour signifier une valeur la présence ou l’absence de courant, de charge ou de tension électrique – suivant qu’il soit question de stocker ou de transmettre une donnée.</p>
<p>Les racines mathématiques de l’<em>ordinateur</em> se retrouvent dans l’étymologie même du terme. En 1955, Fançois Girard, responsable du service publicité d’IBM<sup class="footnote-ref"><a href="#fn19" id="fnref19">19</a></sup> France, fait appel à son ancien professeur de lettres, Jacques Perret, afin de trouver ensemble une traduction au mot anglais “computer”. Perret propose alors l’appellation “ordinatrice électronique”, inspirée de l’<em>ordonnateur</em>, ce composant de la machine décrit par Babbage comme celui qui “prend et reporte les nombres, et les soumet à l’opération demandée”. L’intitulé est ensuite simplifié en <em>ordinateur</em> est entre rapidement dans le langage populaire.</p>
<p>La notion d’informatique est intimement liée à l’univers des ordinateurs. Si en anglais, ordinateur se dit “computer”, la notion d’informatique est tout simplement désignée par la formule “computer science”. Certains penseurs affirment toutefois que l’on ne peut pas définir l’informatique comme “la science des ordinateurs”. On attribue notamment à Edsger Dijkstra, informaticien néerlandais reconnu, l’aphorisme suivant : “L’informatique n’est pas plus la science des ordinateurs que l’astronomie n’est celle des télescopes.” Les auteurs de cette phrase sont en réalité Michael Fellows et Ian Perberry, et la citation complète – traduite – est la suivante :</p>
<blockquote>
<p>L’informatique n’est pas plus la science des ordinateurs que l’astronomie n’est celle des télescopes, la biologie celle des microscopes, ou la chimie celle des <em>béchers</em> et des tubes à essais. La science de traite pas des outils. Elle traite de notre manière des les utiliser, et de ce que l’on découvre en les utilisant. <sup class="footnote-ref"><a href="#fn20" id="fnref20">20</a></sup></p>
</blockquote>
<p>Dans “<em>Qu’est-ce que l’informatique ?</em>”, Franck Varenne propose et critique de nombreuses ébauches définitionnelles – c’est là le cœur de l’ouvrage – avant de conclure par la description suivante :</p>
<blockquote>
<p>[L’informatique est] une technologie (dans son caractère instumental et de délégation opératoire) et une discipline (dans ses versants cognitifs et réthoriques) de démultiplication, d’entrelacement, d’application […] et/ou de confrontation des voies de la référence. Plus brièvement : elle est une technologie d’entrecroisement automatique et programmable des voies de la référence. <sup class="footnote-ref"><a href="#fn21" id="fnref21">21</a></sup></p>
</blockquote>
<p>Varenne nomme “voies de la référence” la faculté des <em>symboles</em> utilisés en informatique (nombres, lettres, signes, etc.) à faire référence à un ou plusieurs autres symboles. En ce qui concerne le calcul numérique, les <em>voies</em> sont au nombre de deux : la <em>concrétisation</em> ou l’<em>abstraction</em>. Si elle en est fondamentalement inspirée, l’informatique va au-delà du calcul et joue sur les niveaux de symboles mis en œuvre : les symboles sont hybridés via des procédés de sous-symbolisation et de simulation. Pour résumer et simplifier cette approche définitionnelle, l’informatique est le croisement de la technologie (l’ordinateur) et de la discipline (la pensée) : elle est l’ensemble qui lie théorie et pratique.</p>
<h2 id="approche-fondamentale">Approche fondamentale</h2>
<p>Les algorithmes se ressemblent : ils sont constitués d’un nombre restreint d’expressions structurantes similaires, que l’on retrouve fréquemment, agencés différemment selon la finalité recherchée. Selon Abiteboul et Dowek, n’importe quel algorithme symbolique peut être exprimé à partir de quatre instructions élémentaires : la séquence, l’affectation, l’itération et la condition.<sup class="footnote-ref"><a href="#fn22" id="fnref22">22</a></sup></p>
<h3 id="séquence">Séquence</h3>
<p>La <em>séquence</em> est l’ordre même dans lequel les instructions sont agencées, c’est-à-dire la structure de l’algorithme elle-même : “fait <em>ceci</em>, puis <em>cela</em>”. Lorsqu’il est représenté – c’est à dire écrit ou dessiné –, on lit classiquement un algorithme de haut en bas, conformément au sens de lecture de nombreux langages. On peut parfois s’émanciper, d’une certaine manière, de cette séquence, notamment en spécifiant expressément à l’algorithme d’éluder une partie des instructions dans certains cas précis. On groupe alors les instructions en ensemble – que l’on peut appeler des <em>fonctions</em> –, auxquels on peut ensuite faire référence. La “tête de lecture”, ou <em>positionnement</em> de l’algorithme à un moment donné de son exécution, ne déroule donc pas nécessairement la structure même cet algorithme de manière linéaire : elle peut effectuer des allers-retours, sauter des parties, y revenir, etc.</p>
<h3 id="affectation">Affectation</h3>
<p>L’affectation est le fait d’attribuer une valeur à une <em>variable</em> – par exemple, “<em>a</em> prend la valeur de <em>b</em>”. Une variable est constituée d’un nom (son identifiant) et d’une valeur unique à chaque instant. Cette valeur peut être numérique (un nombre entier ou décimal, naturel ou relatif), textuelle (un caractère ou une chaîne de caractères) ou encore un booléen : vrai (<em>true</em>) ou faux (<em>false</em>).<sup class="footnote-ref"><a href="#fn23" id="fnref23">23</a></sup> Une variable peut également accueillir un ensemble de données comme un tableau (<em>array</em> en anglais) indexé et/ou associatif. Comme son nom l’indique, une <em>variable</em> peut prendre plusieurs valeurs au cours du temps, à l’exception des constantes – dont la valeur est figée.</p>
<h3 id="itération">Itération</h3>
<p>L’itération, communément appelé <em>boucle</em>, est le fait de répéter une série d’instructions. Ce concept est fondamental, puisque les algorithmes ont généralement pour but d’automatiser des tâches répétitives. On trouve plusieurs types de boucles, en voici une liste non exhaustive :</p>
<ul>
<li>la boucle “pour” (<em>for loop</em> en anglais), qui exécute les instructions pour un nombre donné d’itérations : “répète 10 fois <em>ceci</em>” ;</li>
<li>la boucle “tant que” (<em>while</em> en anglais), qui exécute les instructions tant qu’un énoncé est valide : “tant que <em>ceci</em> est vrai, fait <em>cela</em>” ;</li>
<li>la boucle “pour chaque” (<em>for each</em> en anglais), qui exécute les instructions pour chaque entité d’une liste (des contacts dans un annuaire par exemple) : “<em>pour</em> chaque <em>ceci</em>, fait <em>cela</em>”.</li>
</ul>
<h3 id="condition">Condition</h3>
<p>Enfin, la condition, ou <em>test conditionnel</em>, permet d’effectuer ou non une instruction – ou série d’instructions – selon la valeur d’une variable donnée : par exemple, “si <em>ceci</em> est vrai, faire <em>cela</em>”. On appelle généralement <em>expression conditionnel</em> le schéma “si, alors, sinon” (<em>if, then, else</em>). De plus, on trouve parfois dans ces structures un nombre plus ou moins important d’expressions du type <em>sinon si</em> (<em>else if</em>), qui permettent des conditions imbriquées. Ici encore, cette notion est extrêmement importante, en cela qu’elle permet à un algorithme de prendre des chemins différents, de s’adapter à la complexité éclectique des données réelles qui lui sont fournies, et ainsi d’être plus polyvalent.</p>
<p><code>@TODO</code> : image Keep Talking And Nobody Explodes</p>
<h2 id="algorithmes-pour-quoi-faire-">Algorithmes, pour quoi faire ?</h2>
<h3 id="contextes-dusage-contemporains">Contextes d’usage contemporains</h3>
<h3 id="quatre-familles-de-calcul-numérique">Quatre familles de calcul numérique</h3>
<p>Dominique Cardon propose une classification des typologies d’algorithmes qui régissent notre quotidien, et notamment le web. On peut organiser selon lui le classement de l’information numérique en quatre familles, qu’il illustre spatialement en fonction de la place qu’occupe l’algorithme relativement au monde qu’il entend décrire : “les mesures peuvent se trouver <em>à côté</em>, <em>au-dessus</em>, <em>dans</em> ou <em>en dessous</em> des données numériques”.<sup class="footnote-ref"><a href="#fn24" id="fnref24">24</a></sup> Ces catégories sont également organisées chronologiquement : Cardon précise que si les quatre familles cohabitent aujourd’hui au sein du web contemporain, elles sont en réalité apparues les unes après les autres dans l’histoire d’Internet.</p>
<p><code>@TODO</code> : image tableau</p>
<h3 id="intelligences-artificielles">Intelligences artificielles</h3>
<h1 id="écritures">Écriture(s)</h1>
<h2 id="quest-ce-que-lécriture-">Qu’est-ce que l’écriture ?</h2>
<h2 id="des-langages-naturels-aux-langages-artificiels">Des langages naturels aux langages artificiels</h2>
<ul>
<li>Langages naturels</li>
<li>Langages informatiques (classiques)
<ul>
<li>paradigmes</li>
<li>pseudo-code</li>
<li>langages ésotériques</li>
</ul>
</li>
</ul>
<p><cite>3:36–41</cite></p>
<h2 id="lécriture-algorithmique">L’écriture algorithmique</h2>
<ul>
<li>lignes de code (règles et conventions)
<ul>
<li>conventions de nommage (camelCase, snake_case…)</li>
<li>lisibilité (indentation, syntax highlighting…)</li>
</ul>
</li>
<li>organigrammes (flowcharts)</li>
<li>représentation visuelle (scratch)</li>
<li>modifier l’existant
<ul>
<li>refactoring</li>
<li>versionning (git, commits, diff…)</li>
</ul>
</li>
</ul>
<hr>
<h3 id="état-de-lart-systèmes…">État de l’art (systèmes…)</h3>
<ul>
<li>Problématiques possibles :
<ul>
<li>création</li>
<li>apprentissage</li>
<li>visualiser</li>
<li>jouer</li>
</ul>
</li>
<li>Deux approches :
<ul>
<li>Que permet tel catégorie d’interface/d’écriture algorithme (pour, but, objectif)</li>
<li>Questionner l’interface en soi (pourquoi on écrit en lignes, et pourquoi pas autrement). Travailler le matériau.</li>
</ul>
</li>
<li>Dans quel environnement, quel terrain ?
<ul>
<li>Creative coding</li>
<li>Live coding</li>
<li>…</li>
</ul>
</li>
</ul>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Serge Abiteboul est checheur à l’<abbr title="Institut national de recherche en informatique et en automatique">INRIA</abbr>  et professeur à l’<abbr title="École normale supérieure">ENS</abbr> de Paris-Saclay. Sa recherche porte sur la gestion de données, d’information et de connaissances. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>Gilles Dowek est également chercheur à l’<abbr title="Institut national de recherche en informatique et en automatique">INRIA</abbr> et professeur à l’<abbr title="École normale supérieure">ENS</abbr> de Paris-Saclay. Ses travaux portent notamment sur la formalisation des mathématiques et les systèmes de traitement des démonstrations. <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p><cite>1:11</cite> <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p>Muhammad Ibn Mūsā al-Khuwārizmī, généralement appelé <em>Al-Khwarizmin</em> (latinisé en <em>Algoritmi</em>), était un mathématicien, géographe, astrologue et astronome perse, notamment auteur d’un ouvrage classifiant les procédés algébriques existants à son époque. <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p>Le terme <em>abaque</em> désigne tout instrument mécanique plan facilitant le calcul. <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p>Blaise Pascal était un mathématicien, physicien, inventeur et philosophe français. À 19 ans, il invente la première machine à calculer, dénommée <em>machine d’arithmétique</em>, puis <em>pascaline</em>. <a href="#fnref6" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p>Gottfried Leibniz était un philosophe, scientifique, mathématicien et logicien allemand. <a href="#fnref7" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p>Charles Babbage était un mathématicien et inventeur britannique du XIX<sup>ème</sup> siècle. Il fut l’un des principaux précurseurs de l’informatique. <a href="#fnref8" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn9" class="footnote-item"><p><a href="https://fr.wikipedia.org/wiki/Machine_analytique">Machine analytique</a> sur Wikipédia <a href="#fnref9" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn10" class="footnote-item"><p>En mathématiques, les nombres de Bernoulli constituent une suite de nombres rationnels. Ces nombres ont d’abord été étudiés par Jacques Bernoulli, mathématicien et physicien suisse du XVII<sup>ème</sup>siècle. <a href="#fnref10" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn11" class="footnote-item"><p>Alan Turing était un mathématicien et cryptologue britannique, dont les travaux ont fondé l’informatique moderne. Après l’invention de la machine de Turing – qui contribue à la thèse de Church-Turing autour de la notion de problème <em>calculable</em> –, il participe au décryptage des codes secrets de la machine allemande Enigma pendant la Seconde Guerre Mondiale – ce qui joua un rôle essentiel dans la victoire des Alliés. Turing poursuit des recherches en informatique et formule le “test de Turing”, fondamental dans le champ de l’intelligence artificielle. Poursuivi judiciairement pour homosexualité, Turing choisit la castration chimique pour éviter la prison. Il décède en 1954 d’un empoisonnement au cyanure, vraisemblablement par suicide. <a href="#fnref11" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn12" class="footnote-item"><p><cite>3:16–18</cite> <a href="#fnref12" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn13" class="footnote-item"><p><a href="https://fr.wikipedia.org/wiki/Architecture_de_von_Neumann#Architecture">Architecture de von Neumann</a> sur Wikipédia <a href="#fnref13" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn14" class="footnote-item"><p><a href="https://fr.wikipedia.org/wiki/Programme_informatique">Programme informatique</a> sur Wikipédia <a href="#fnref14" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn15" class="footnote-item"><p><cite>3:46</cite> <a href="#fnref15" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn16" class="footnote-item"><p><cite>4</cite> <a href="#fnref16" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn17" class="footnote-item"><p><a href="https://fr.wikipedia.org/wiki/What_you_see_is_what_you_get"><em>What you see is what you get</em></a> sur Wikipédia <a href="#fnref17" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn18" class="footnote-item"><p>Le <em>bit</em>, abréviation de <em>binary digit</em> (chiffre binaire) est l’unité d’information la plus basique : un chiffre binaire ne peut avoir que deux valeurs, et ainsi être représenté avec un dispositif à deux états. Ces valeurs d’états sont le plus souvent représentés comme 0 ou 1. <a href="#fnref18" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn19" class="footnote-item"><p>International Business Machines Corporation, connue sous l’abréviation IBM, est une société multinationale américaine fondée en 1911. Il s’agit d’un des leaders mondiaux en informatique – parallèlement sur le matériel, les services, les logiciels et la recherche. <a href="#fnref19" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn20" class="footnote-item"><p><cite>5</cite> <a href="#fnref20" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn21" class="footnote-item"><p><cite>3:67</cite> <a href="#fnref21" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn22" class="footnote-item"><p><cite>1:18–19</cite> <a href="#fnref22" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn23" class="footnote-item"><p>Un booléen est un type de variable à deux états. Cette terminologie fait référence aux travaux de George Boole, célèbre logicien et mathématicien  britannique, qui en 1845 a établit les bases de la “logique booléenne”, n’acceptant que deux valeurs numériques : 0 et 1. Cet algèbre connaîtra une importance capitale dans l’informatique et est encore énormément employée de nos jours. <a href="#fnref23" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn24" class="footnote-item"><p><cite>2:17</cite> <a href="#fnref24" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>

    </div>
  </div>
</body>

</html>
